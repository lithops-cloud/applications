{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AirBnB sentiment analysis of the comments from multiple cities\n",
    "\n",
    "In this notebook, sentiment analysis of airbnb dataset is performed over cloud functions using lithops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "### Complete set of datasets (requires IBM Cloud account)\n",
    "\n",
    "Login to the IBM Watson Studio, first you need to activate watson services on your account to access the download links below. After downloading the Airbnb dataset, upload it to a cloud bucket. The dataset consists of information -like review, reviewer info, coordinates- of the reviews from Airbnb.\n",
    "\n",
    "### Sample datasets (requires AWS account)\n",
    "\n",
    "Follow the instructions in the [README](../README.md) to import the set of public data into your custom bucket.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the dependencies within an execution environment with the attached [requirements.txt](./requirements.txt) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a runtime with the necessary dependencies for cloud functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNTIME_NAME = \"lithops-airbnb-runtime:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lithops runtime build -b aws_lambda -f runtime/Dockerfile.py3.10 $RUNTIME_NAME --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import time\n",
    "import shutil\n",
    "import csv\n",
    "import lithops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should replace BUCKET with your bucket name in which you put the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = ['s3://BUCKET']\n",
    "# Examples:\n",
    "# IBM Cloud Object Storage: \"cos://airbnb-dataset/\"\n",
    "# AWS S3: \"s3://airbnb-dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can edit the dataset from this block deleting the filenames you don't want to perform sentiment analysis on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = {'amsterdam-2016-01-03-reviews.csv': 'Amsterdam',\n",
    "           'antwerp-2015-10-03-reviews.csv': 'Antwerp Belgium',\n",
    "           'athens-2015-07-17-reviews.csv': 'Athens Europe',\n",
    "           'austin-2015-11-07-reviews.csv': 'Austin',\n",
    "           'barcelona-2016-01-03-reviews.csv': 'Barcelona',\n",
    "           'berlin-2015-10-03-reviews.csv': 'Berlin',\n",
    "           'boston-2015-10-03-reviews.csv': 'Boston',\n",
    "           'brussels-2015-10-03-reviews.csv': 'Brussels',\n",
    "           'chicago-2015-10-03-reviews.csv': 'Chicago',\n",
    "           'dublin-2016-01-06-reviews.csv': 'Dublin',\n",
    "           'london-2016-02-02-reviews.csv': 'London',\n",
    "           'los-angeles-2016-01-02-reviews.csv': 'Los Angeles',\n",
    "           'madrid-2015-10-02-reviews.csv': 'Madrid',\n",
    "           'mallorca-2016-01-06-reviews.csv': 'Palma Mallorca Spain',\n",
    "           'melbourne-2016-01-03-reviews.csv': 'Melbourne',\n",
    "           'montreal-2015-10-02-reviews.csv': 'Montreal',\n",
    "           'nashville-2015-10-03-reviews.csv': 'Nashville',\n",
    "           'new-orleans-2015-09-02-reviews.csv': 'New Orleans',\n",
    "           'new-york-city-2016-02-02-reviews.csv': 'New York City',\n",
    "           'oakland-2015-06-22-reviews.csv': 'Oakland',\n",
    "           'paris-2015-09-02-reviews.csv': 'Paris',\n",
    "           'portland-2016-01-01-reviews.csv': 'Portland',\n",
    "           'san-diego-2015-06-22-reviews.csv': 'San Diego',\n",
    "           'san-francisco-2015-11-01-reviews.csv': 'City of San Francisco',\n",
    "           'santa-cruz-county-2015-10-15-reviews.csv': 'Santa Cruz',\n",
    "           'seattle-2016-01-04-reviews.csv': 'Seattle',\n",
    "           'sydney-2016-01-03-reviews.csv': 'Sydney',\n",
    "           'toronto-2015-09-03-reviews.csv': 'Toronto',\n",
    "           'trentino-2015-10-12-reviews.csv': 'Trento',\n",
    "           'vancouver-2015-12-03-reviews.csv': 'Vancouver',\n",
    "           'venice-2015-07-18-reviews.csv': 'Venice Italy',\n",
    "           'vienna-2015-07-18-reviews.csv': 'Vienna Austria.',\n",
    "           'washington-dc-2015-10-03-reviews.csv': 'Washington D.C.',\n",
    "           \"Amsterdam-2024-09-06-reviews.csv\": \"Amsterdam\",\n",
    "           \"Barcelona-2024-09-11-reviews.csv\": \"Barcelona\",\n",
    "           \"Berlin-2024-09-28-reviews.csv\": \"Berlin\",\n",
    "           \"Montreal-2024-09-13-reviews.csv\": \"Montreal\",\n",
    "           \"Portland-2024-09-05-reviews.csv\": \"Portland\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`analyze_comments` function parses dataset and classifies them by their sentiment group. This function is the **map function** in our map-reduce paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_comments(obj):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    city = DATASET[obj.key]\n",
    "    print('City: {}'.format(city))\n",
    "    print('Copying dataset to local disk')\n",
    "    with open('/tmp/{}.csv'.format(city), 'wb') as csvfile:\n",
    "        shutil.copyfileobj(obj.data_stream, csvfile)\n",
    "    print('Finished copying dataset to local disk')\n",
    "    print('Parsing dataset')\n",
    "    pos, neg, neu = 0, 0, 0\n",
    "    positive, neutral, negative = [], [], []\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    with open('/tmp/{}.csv'.format(city), encoding='latin1') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if len(row) < 11:\n",
    "                continue\n",
    "            vs = analyzer.polarity_scores(str(row[5]))\n",
    "            if vs['compound'] >= 0.4:\n",
    "                pos += 1\n",
    "                if (row[8], row[9]) not in positive:\n",
    "                    positive.append((row[8], row[9]))\n",
    "            elif vs['compound'] < 0.4 and vs['compound'] > -0.4:\n",
    "                neu += 1\n",
    "                if (row[8], row[9]) not in neutral:\n",
    "                    neutral.append((row[8], row[9]))\n",
    "            else:\n",
    "                neg += 1\n",
    "                if (row[8], row[9]) not in negative:\n",
    "                    negative.append((row[8], row[9]))\n",
    "    print('Finished parsing dataset')\n",
    "    return {'city': city, 'comments': {'positive': pos, 'neutral': neu, 'negative': neg},\n",
    "            'coordinates': {'positive': positive, 'neutral': neutral, 'negative': negative}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_map` function is the **reduce function** in this example. It reduces all the intermediate data grouped by sentiments and draws a map displaying the results in different colors accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(results):\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    from geopy.geocoders import Nominatim\n",
    "    city = None\n",
    "    comments = None\n",
    "    coordinates = None\n",
    "    for data in results:\n",
    "        if data is None:\n",
    "            continue\n",
    "        if city is None:\n",
    "            city = data['city']\n",
    "        partial_comments = data['comments']\n",
    "        partial_coordinates = data['coordinates']\n",
    "        if not comments:\n",
    "            comments = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "        if not coordinates:\n",
    "            coordinates = {'positive': [], 'neutral': [], 'negative': []}\n",
    "        comments['positive'] += partial_comments['positive']\n",
    "        comments['neutral'] += partial_comments['neutral']\n",
    "        comments['negative'] += partial_comments['negative']\n",
    "        coordinates['positive'] += partial_coordinates['positive']\n",
    "        coordinates['neutral'] += partial_coordinates['neutral']\n",
    "        coordinates['negative'] += partial_coordinates['negative']\n",
    "    print('Rendering Maps')\n",
    "    plt.switch_backend('agg')\n",
    "    plt.figure(figsize=(6.7, 6.7), dpi=96)\n",
    "    geolocator = Nominatim(user_agent=\"lithops\")\n",
    "    loc = geolocator.geocode(city)\n",
    "    if not loc:\n",
    "        print(\"Could not locate {}\".format(city))\n",
    "        raise Exception(\"Could not locate {}\".format(city))\n",
    "    m = Basemap(llcrnrlon=loc.longitude-0.12, llcrnrlat=loc.latitude-0.12,\n",
    "                urcrnrlon=loc.longitude+0.12, urcrnrlat=loc.latitude+0.12,\n",
    "                projection='lcc', resolution='l', epsg=4263,\n",
    "                lat_0=loc.latitude, lon_0=loc.longitude)\n",
    "\n",
    "    # World_Topo_Map\n",
    "    # NatGeo_World_Map\n",
    "    # World_Street_Map\n",
    "    # ESRI_StreetMap_World_2D\n",
    "    m.arcgisimage(service='NatGeo_World_Map', xpixels=500, verbose=False)\n",
    "\n",
    "    # Positive\n",
    "    lats = []\n",
    "    longs = []\n",
    "    for coord in coordinates['positive']:\n",
    "        lat, long = coord\n",
    "        try:\n",
    "            lats.append(float(lat))\n",
    "            longs.append(float(long))\n",
    "        except Exception:\n",
    "            pass\n",
    "    m.scatter(longs, lats, marker='o', color='g', alpha=1, s=0.3)\n",
    "\n",
    "    # neutral\n",
    "    lats = []\n",
    "    longs = []\n",
    "    for coord in coordinates['neutral']:\n",
    "        lat, long = coord\n",
    "        try:\n",
    "            lats.append(float(lat))\n",
    "            longs.append(float(long))\n",
    "        except Exception:\n",
    "            pass\n",
    "    m.scatter(longs, lats, marker='o', color='b', alpha=0.3, s=0.2)\n",
    "\n",
    "    # negative\n",
    "    lats = []\n",
    "    longs = []\n",
    "    for coord in coordinates['negative']:\n",
    "        lat, long = coord\n",
    "        try:\n",
    "            lats.append(float(lat))\n",
    "            longs.append(float(long))\n",
    "        except Exception:\n",
    "            pass\n",
    "    m.scatter(longs, lats, marker='o', color='r', alpha=0.3, s=0.2)\n",
    "    imgdata = io.BytesIO()\n",
    "    plt.savefig(imgdata, format='png', bbox_inches='tight', pad_inches=0, dpi=96)\n",
    "    imgdata.seek(0)  # rewind the data\n",
    "    image_string = base64.encodebytes(imgdata.getvalue())\n",
    "    print('Finished rendering map')\n",
    "    return {'city': city, 'comments': comments, 'map': image_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lithops.config import load_config\n",
    "import os\n",
    "\n",
    "plot_dst = \"plots/test\"\n",
    "os.makedirs(plot_dst, exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lithops_config = load_config()\n",
    "    backend = lithops_config['lithops']['backend']\n",
    "    if backend == 'aws_lambda':\n",
    "        runtime_memory = 1769\n",
    "    else:\n",
    "        runtime_memory = 2048\n",
    "\n",
    "    t0 = time.time()\n",
    "    fexec = lithops.FunctionExecutor(runtime=RUNTIME_NAME, runtime_memory=runtime_memory)\n",
    "    fexec.map_reduce(analyze_comments, BUCKET, create_map, obj_reduce_by_key=True)\n",
    "    # fexec.map(analyze_comments, BUCKET)\n",
    "    results = fexec.get_result()\n",
    "    for res in results:\n",
    "        with open(\"maps/{}.png\".format(res['city']), \"wb\") as i:\n",
    "            i.write(base64.b64decode(res['map']))\n",
    "        print('{}: {}'.format(res['city'], res['comments']))\n",
    "    print('Total time: {} seconds'.format(round(time.time()-t0, 2)))\n",
    "    fexec.plot(dst='plots/test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
